{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "def get_data(dir_list):\n",
    "    \n",
    "    with open('../swl.txt', 'r', encoding = 'utf-8') as f:\n",
    "        stop_words = f.read()   \n",
    "    train_reviews = {'review': [], 'label': []}\n",
    "    test_reviews = {'review': [], 'label': []}\n",
    "    for directory in dir_list:\n",
    "        for review in os.listdir(directory):\n",
    "            clean_review = ''\n",
    "            if review != '.ipynb_checkpoints':\n",
    "                review_body = open(directory + '/' + review, 'r', encoding = 'utf-8').read()\n",
    "                #print(type(review_body))\n",
    "                if 'bad' in review:\n",
    "                    label = '-1'\n",
    "                elif 'good' in review:\n",
    "                    label = '1'                  \n",
    "                else:\n",
    "                    print('error!')\n",
    "                for word in review_body.split():\n",
    "                    \n",
    "                    if word not in stop_words:\n",
    "                        clean_review += word + ' '\n",
    "                    \n",
    "            if 'train' in directory:\n",
    "                train_reviews['review'].append(clean_review)\n",
    "                train_reviews['label'].append(label)\n",
    "            if 'test' in directory:\n",
    "                test_reviews['review'].append(clean_review)\n",
    "                test_reviews['label'].append(label)\n",
    "    
    "    return (train_reviews, test_reviews)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "     # Data directories \n",
    "    dir_list = ['binary_twice_merged_corpus/train', 'binary_twice_merged_corpus/test']\n",
    "    dir_list2 = ['./binary_full_corpus/train', './binary_full_corpus/test']\n",
    "    #dir_list2 = ['lemmatized_corpus_no_punct/train', 'lemmatized_corpus_no_punct/test']\n",
    "    #dir_list2 = ['./relevant_sentences_corpus/train', './relevant_sentences_corpus/test']\n",
    "    # Call the get_data() method \n",
    "    data1 = get_data(dir_list)    \n",
    "    data2 = get_data(dir_list2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.86      0.96      0.91       100\n",
      "          1       0.96      0.85      0.90       101\n",
      "\n",
      "avg / total       0.91      0.91      0.91       201\n",
      "\n",
      "Decision tree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      1.00      1.00       100\n",
      "          1       1.00      1.00      1.00       100\n",
      "\n",
      "avg / total       1.00      1.00      1.00       200\n",
      "\n",
      "Random Forrest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.98      0.98      0.98       100\n",
      "          1       0.98      0.98      0.98       101\n",
      "\n",
      "avg / total       0.98      0.98      0.98       201\n",
      "\n",
      "MultinomialNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.83      0.86      0.84       100\n",
      "          1       0.86      0.82      0.84       101\n",
      "\n",
      "avg / total       0.84      0.84      0.84       201\n",
      "\n",
      "KNeighbor\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.68      0.73      0.70       100\n",
      "          1       0.71      0.65      0.68       101\n",
      "\n",
      "avg / total       0.69      0.69      0.69       201\n",
      "\n",
      "Nearest Centroid\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.81      0.87      0.84       100\n",
      "          1       0.86      0.80      0.83       100\n",
      "\n",
      "avg / total       0.84      0.83      0.83       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    train_reviews = data1[0]\n",
    "    test_reviews =  data1[1]\n",
    "    \n",
    "    train_reviews2 = data2[0]\n",
    "    test_reviews2 =  data2[1]\n",
    "    \n",
    "    X_train = train_reviews['review']\n",
    "    X_test = test_reviews['review']\n",
    "    y_train = train_reviews['label']\n",
    "    y_test = test_reviews['label']\n",
    "    \n",
    "    \n",
    "    x_train2 = train_reviews2['review']\n",
    "    X_test2 = test_reviews2['review']\n",
    "    y_train2 = train_reviews2['label']\n",
    "    y_test2 = test_reviews2['label']\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    clfs = {\n",
    "    'Naive_bayes': MultinomialNB(),\n",
    "    'SVM': LinearSVC(),\n",
    "    'Decision_tree': tree.DecisionTreeClassifier(),\n",
    "    'Random Classifier': RandomForestClassifier(n_estimators=100),\n",
    "    'KNeighbours': KNeighborsClassifier()       \n",
    "    \n",
    "    }\n",
    "    \n",
    "    
    "    
    "    print('SVM')\n",
    "    text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', LinearSVC()),\n",
    "                         ])\n",
    "\n",
    "    text_clf.fit(X_train, y_train)\n",
    "\n",
    "    predicted = text_clf.predict(X_test2)\n",
    "\n",
    "    print(metrics.classification_report(y_test2, predicted))\n",
    "\n",
    "\n",
    "    print('Decision tree')\n",
    "    from sklearn import tree\n",
    "\n",
    "\n",
    "    text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', tree.DecisionTreeClassifier()),\n",
    "                         ])\n",
    "\n",
    "    text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    predicted = text_clf.predict(X_test)\n",
    "\n",
    "    print(metrics.classification_report(y_test, predicted)) #\n",
    "\n",
    "    print('Random Forrest')\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', RandomForestClassifier(n_estimators=100)),\n",
    "                         ])\n",
    "\n",
    "    text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    predicted = text_clf.predict(X_test2)\n",
    "\n",
    "    print(metrics.classification_report(y_test2, predicted))\n",
    "\n",
    "    print('MultinomialNB')\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "    text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', MultinomialNB()),\n",
    "                         ])\n",
    "\n",
    "    text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    predicted = text_clf.predict(X_test2)\n",
    "\n",
    "    print(metrics.classification_report(y_test2, predicted))\n",
    "\n",
    "    print('KNeighbor')\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', KNeighborsClassifier()),\n",
    "                         ])\n",
    "\n",
    "    text_clf.fit(X_train, y_train)\n",
    "\n",
    "    predicted = text_clf.predict(X_test2)\n",
    "\n",
    "    print(metrics.classification_report(y_test2, predicted))\n",
    "\n",
    "    print('Nearest Centroid')\n",
    "    from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "\n",
    "    text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', NearestCentroid()),\n",
    "                         ])\n",
    "\n",
    "    text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    predicted = text_clf.predict(X_test)\n",
    "\n",
    "    print(metrics.classification_report(y_test, predicted))\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
