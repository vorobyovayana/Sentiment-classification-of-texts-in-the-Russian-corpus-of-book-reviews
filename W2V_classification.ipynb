{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Anaconda/lib/python3.6/site-packages/gensim/models/doc2vec.py:580: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "/home/user/Anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:39: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "/home/user/Anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:57: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
     ]
    }
   ],
   "source": [
    "# gensim modules\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# numpy\n",
    "import numpy\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# random\n",
    "import random\n",
    "\n",
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, sources):\n",
    "        self.sources = sources\n",
    "        \n",
    "        flipped = {}\n",
    "        \n",
    "        # make sure that keys are unique\n",
    "        for key, value in sources.items():\n",
    "            if value not in flipped:\n",
    "                flipped[value] = [key]\n",
    "            else:\n",
    "                raise Exception('Non-unique prefix encountered')\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    yield LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no])\n",
    "    \n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no]))\n",
    "        return self.sentences\n",
    "    \n",
    "    def sentences_perm(self):\n",
    "        shuffled = list(self.sentences)\n",
    "        random.shuffle(shuffled)\n",
    "        return shuffled\n",
    "    \n",
    "#sources = {'test_neg.txt':'TEST_NEG', 'test_pos.txt':'TEST_POS', 'train_neg.txt':'TRAIN_NEG', 'train_pos.txt':'TRAIN_POS'}\n",
    "\n",
    "sources = {'test_neg.txt':'TEST_NEG', 'test_pos.txt':'TEST_POS', 'test_neu.txt': 'TEST_NEU','train_neg.txt':'TRAIN_NEG', 'train_pos.txt':'TRAIN_POS', 'train_neu.txt': 'TRAIN_NEU' }\n",
    "sentences = LabeledLineSentence(sources)\n",
    "\n",
    "model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=7)\n",
    "\n",
    "model.build_vocab(sentences.to_array())\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train(sentences.sentences_perm(), total_examples=model.corpus_count, epochs=model.iter)\n",
    "\n",
    "\n",
    "model.save('./imdb2.d2v')\n",
    "model = Doc2Vec.load('./imdb2.d2v')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47419265  0.22265063 -0.46373898  0.29644212  0.24933659 -0.03566697\n",
      "  0.95894581  0.49829221  0.40344387 -0.21912631  0.00672929  0.45505264\n",
      "  0.45625553  0.27178591  0.15036167 -0.711007    0.64220738 -0.25538936\n",
      " -0.19682243 -0.11161936 -0.55217767 -0.8003155  -0.23982289 -0.19997309\n",
      "  0.09913149 -0.96925551  1.30868506 -0.25909501 -0.00620278 -0.63689172\n",
      " -0.04055128  0.00948371  0.95462632  0.15182315  0.16749103  0.13801953\n",
      "  0.38410836 -0.80300552  0.40023613  0.68217188 -0.35519913 -0.80504477\n",
      " -0.26363084 -0.23686907  0.46063983 -0.69996244 -0.15165094  0.01434649\n",
      " -0.24660118 -0.34766579 -0.88195491 -0.37955654  0.2783905   0.29337656\n",
      "  0.13391115 -0.20515758 -0.63516182  0.87443525 -0.90199155 -0.09723683\n",
      " -0.01127618 -0.02132701 -0.39249209 -0.67206371  0.19638811  0.4132849\n",
      " -0.13170499  0.59632611 -0.89579099 -0.76429737 -0.39151546 -0.53849131\n",
      "  1.36337841 -0.51752335  0.04309887 -0.47788385  0.82222766 -0.75321454\n",
      " -0.07771119 -0.23919851  0.2561022  -0.47832492  0.9118973  -0.27333128\n",
      " -0.54130995  0.30733636 -0.99423283  0.79319233  0.40387204  0.06512322\n",
      " -0.36063948  0.50539875  0.19069168  0.75704759 -0.50961888 -0.46855992\n",
      " -0.62797779 -0.14037757  0.10221582 -0.53152758]\n"
     ]
    }
   ],
   "source": [
    "#print(model.most_similar('книга'))\n",
    "    \n",
    "\n",
    "print(model['TEST_NEG_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.06430757 -0.04599246 -1.07595217 ..., -1.65198135 -1.24342155\n",
      "   0.30501071]\n",
      " [ 1.00206351  1.96291304  3.28503036 ...,  0.3572861  -1.08156443\n",
      "  -1.51788533]\n",
      " [-0.56483889  0.20518304 -0.8927598  ..., -0.89522284 -1.06609261\n",
      "  -0.84506726]\n",
      " ..., \n",
      " [-0.45927173  0.1324628  -0.33953124 ...,  0.13001081 -0.48279086\n",
      "  -1.35075331]\n",
      " [ 0.16524084 -1.84224975 -0.86276621 ...,  0.05120652 -0.90570652\n",
      "  -0.10345212]\n",
      " [-0.40863401  0.82991469  1.13864255 ..., -0.28418246 -1.064291\n",
      "   0.34514821]]\n",
      "[ 1.  1.  1. ...,  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55666666666666664"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_arrays = numpy.zeros((800, 100))\n",
    "#train_labels = numpy.zeros(800)\n",
    "\n",
    "train_arrays = numpy.zeros((1200, 100))\n",
    "train_labels = numpy.zeros(1200)\n",
    "\n",
    "#for i in range(400):\n",
    "for i in range(400):\n",
    "    prefix_train_pos = 'TRAIN_POS_' + str(i)\n",
    "    prefix_train_neg = 'TRAIN_NEG_' + str(i)\n",
    "    prefix_train_neu= 'TRAIN_NEU_' + str(i)\n",
    "    train_arrays[i] = model[prefix_train_pos]\n",
    "    train_arrays[400 + i] = model[prefix_train_neg]\n",
    "    train_arrays[800 + i] = model[prefix_train_neu]\n",
    "    train_labels[i] = 1\n",
    "    train_labels[400 + i] = -1\n",
    "    train_labels[800 + i] = 0\n",
    "    \n",
    "print(train_arrays)\n",
    "\n",
    "print(train_labels)\n",
    "\n",
    "\n",
    "test_arrays = numpy.zeros((300, 100))\n",
    "test_labels = numpy.zeros(300)\n",
    "\n",
    "for i in range(100):\n",
    "    prefix_test_pos = 'TEST_POS_' + str(i)\n",
    "    prefix_test_neg = 'TEST_NEG_' + str(i)\n",
    "    prefix_test_neu= 'TEST_NEU_' + str(i)\n",
    "    test_arrays[i] = model[prefix_test_pos]\n",
    "    test_arrays[100 + i] = model[prefix_test_neg]\n",
    "    test_arrays[200 + i] = model[prefix_test_neu]\n",
    "    test_labels[i] = 1\n",
    "    test_labels[100 + i] = -1\n",
    "    test_labels[200 + i] = 0\n",
    "    \n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_arrays, train_labels)\n",
    "\n",
    "classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
